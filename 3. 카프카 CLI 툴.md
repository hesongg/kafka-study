# 3. 카프카 CLI 툴
## 인프런 - "[아파치 카프카 애플리케이션 프로그래밍] 개념부터 컨슈머, 프로듀서, 커넥트, 스트림즈까지!" 를 보고 정리한 내용

<br>

### 카프카 커맨드 라인 툴

- 토픽이나 파티션 개수 변경과 같은 명령을 실행해야하는 경우 자주 발생
- 카프카 CLI 툴과 각 툴별 옵션에 대해 알고있어야 한다.
- 카프카의 명령어들은 관련 애플리케이션 개발 및 클러스터 운영 시 자주 쓰인다.
- CLI 툴을 통해 토픽 관련 명령을 실행할 때 필수 옵션과 선택 옵션이 있음
    - 선택 옵션은 지정하지 않을시 브로커에 설정된 기본 설정 값 또는 커맨드 라인 툴의 기본값으로 대체되어 설정된다.
    - 그러므로 CLI 툴을 사용하기 전에 현재 브로커에 옵션이 어떻게 설정되어 있는지 확인한 후에 사용하자.
    - ex) 특정 토픽에대해서 실제 사용할 파티션의 개수가 5개인데, 브로커의 설정된 기본 파티션 개수가 10개인데 토픽 생성시 옵션을 지정해주지 않으면 브로커 설정 값으로 파티션 10개 생성
        - 파티션 개수는 다시 줄이기 불가능하기때문에 문제가 될 수 있음
<br>

#### 실행 관련

- 실행
    - 카프카 설치 및 config 설정 후, 설치 경로에서 주키퍼 실행 후 -> 카프카 실행
    - ```bin/zookeeper-server-start.sh config/zookeeper.properties```
    - ```bin/kafka-server-start.sh config/server.properties```
    
- 브로커 내부에 설정된 옵션 값 조회
    - ```bin/kafka-broker-api-versions.sh --bootstrap-server localhost:9092```
    
- 부트스트랩 서버의 토픽 리스트 조회
    - ```bin/kafka-topics.sh --bootstrap-server localhost:9092 --list```

<br>

#### kafka-topics.sh

- 카프카 클러스터 정보와 토픽 이름만으로 토픽 생성 가능
    - 클러스터 정보와 토픽 이름은 토픽을 만들기 위한 필수 값
    - 토픽은 파티션 개수, 복제 개수 등과 같이 다양한 옵션이 포함되어 있지만 모두 브로커에 설정된 기본 값으로 생성된다.

- 토픽 생성
    - ```bin/kafka-topics.sh --create --bootstrap-server my-kafka:9092 --topic hello.kafka```

- 토픽 설명 조회
    - ```bin/kafka-topics.sh --bootstrap-server my-kafka:9092 --topic hello.kafka --describe```

- 특정 설정으로 토픽 생성
  ```
  bin/kafka-topics.sh --create --bootstrap-server my-kafka:9092 --partitions 10 --replication-factor 1 --topic hello.kafka2 --config retention.ms=172800000
  ```

- 설정 변경 (파티션 10으로 증가)
  ```
  bin/kafka-topics.sh --bootstrap-server my-kafka:9092 --topic test --alter --partitions 10
  ``` 

- 파티션 줄이는 명령어를 수행하면 오류가 발생한다.
    - <img width="841" alt="image" src="https://github.com/hesongg/kafka-study/assets/77953474/a29c21d0-0972-4851-89c2-1ad34dab964a">
    - 다시 줄이기는 어려우니 파티션을 늘릴 때는 꼭 주의해서 설정하자.

<br>

#### kafka-configs.sh

- --alter 와 --add-config 옵션을 사용하여 min.insync.replicas 옵션을 토픽별로 설정 가능
- ```min.insync.replicas```
    - 프로듀서로 데이터를 보낼 때, 컨슈머가 읽을 때 워터마크 용도로도 사용되고
    - 얼마나 안전하게 데이터를 주고 받을지 명확하게 설정할 때 사용되기도 한다.
- 브로커에 설정된 각종 기본 값은 --broker, --all, --describe 옵션을 사용하여 조회 가능
    - 또는 브로커의 server.properties 파일을 보던가..

- 강의와 다르게 kafka-topis.sh 의 --describe 옵션으로 기본 설정된 retention 기간은 따로 안보이는데 뭘까?
    - default config 는 안보이는건지..

- min.insyunc.replicas 옵션 변경
    ```
    bin/kafka-configs.sh --bootstrap-server my-kafka:9092 --alter --add-config min.insync.replicas=2 --topic test
    ``` 

- 카프카 브로커에 설정된 다양한 옵션 값 조회
    ```
    bin/kafka-configs.sh --bootstrap-server my-kafka:9092 --broker 0 --all --describe
    ```

<br>

#### kafka-console-producer.sh

- 토픽에 데이터를 넣을 수 있는 명령어

- 메시지 키를 가지는 레코드를 전송하기 위해서는 몇가지 추가 옵션 작성 필요
    - ```key.separator``` 를 선언하지 않으면 기본 설정은 Tab delimeter(₩t) 이므로 선언하지 않고 메시지를 보내려면 메시지 키를 작성하고 탭키를 누른 뒤 메시지 값을 작성하고 엔터를 누른다.
    - ```parse.key=true``` 옵션도 설정
    - 이러한 옵션을 신경 쓰지 않으면 메시지 키가 null 로 설정될 수 있다

- 동일한 키를 가진 레코드들은 토픽의 동일한 파티션으로 저장됨
    - 이렇게 프로듀서에서 메시지키를 지정하여 레코드를 전송하면 데이터 순서 처리 가능 

- 메시지 키가 null 인 경우에는 프로듀서가 파티션으로 전송할 때 레코드 배치 단위로 라운드 로빈으로 전송함    

- 데이터 전송
    ```
    bin/kafka-console-producer.sh --bootstrap-server my-kafka:9092 --topic hello.kafka
    ```
    - <img width="397" alt="image" src="https://github.com/hesongg/kafka-study/assets/77953474/941a4949-95ab-4432-a897-de30d459eee6">
    
- 메시지 키 지정하여 데이터 전송
    ```
    bin/kafka-console-producer.sh --bootstrap-server my-kafka:9092 --topic hello.kafka --property "parse.key=true" --property "key.separator=:"
    ```
    - key value separator 를 ":" 로 지정함
    - <img width="301" alt="image" src="https://github.com/hesongg/kafka-study/assets/77953474/3dae2778-b6ad-4343-b965-d768178f5310">
    - k1 key 를 가지는 레코드들은 동일한 파티션으로 전달된다.

<br>

#### kafka-console-consumer.sh

- 이 CLI 툴은 이름과 같이 컨슈머 역할을 한다.
- 특정 토픽에 있는 데이터를 컨슘해서 안에 있는 데이터를 임시적으로 조회하기위한 용도로 사용
- 필수 옵션으로 --bootstrap-server 에 카프카 클러스터 정보, --topic 에 토픽 이름이 필요
- 추가로 --from-beginning 옵션을 주면 토픽에 저장된 가장 처음 데이터부터 출력한다.
    - 해당 옵션을 설정하지 않으면 실시간으로 들어오고 있는 데이터들만 출력함

- kafka-console-producer.sh 로 보낸 메시지 값이 출력된 것을 확인 가능
- 만약 레코드의 메시지 키와 메시지 값을 확인하고 싶다면 --property 옵션을 사용하면 된다.
    - ```--property print.key=true```
    - ```--property key.separator=-```

- --max-messages
    - 최대 컨슘 메시지 개수 설정
- --partition
    - 옵션을 사용하면 특정 파티션만 컨슘 가능
- --group
    - 컨슈머 그룹을 기반으로 kafka-console-consumer 가 동작한다.
    - 컨슈머 그룹의 역할?
        - 특정 오프셋 까지의 데이터를 커밋시키기위한 용도로 사용
    - 컨슈머 그룹으로 토픽의 레코드를 가져갈 경우 어느 레코드까지 읽었는지에 대한 데이터가 카프카 브로커에 저장된다.

- 특정 토픽 메시지 처음부터 출력
    ```
    bin/kafka-console-consumer.sh --bootstrap-server my-kafka:9092 --topic hello.kafka --from-beginning
    ```
    - <img width="399" alt="image" src="https://github.com/hesongg/kafka-study/assets/77953474/9ea647b1-2a4b-47a6-8b00-ac78f1c4135a">

- 처음부터 읽는데, 메시지 키도 함께 출력
    ```
    bin/kafka-console-consumer.sh --bootstrap-server my-kafka:9092 --topic hello.kafka --from-beginning --property print.key=true --property key.separator="-" --from-beginning
    ```
    - <img width="236" alt="image" src="https://github.com/hesongg/kafka-study/assets/77953474/cd2e0191-0ebe-47c4-9c2f-795e63d97ed6">

- 위의 내용에 max message 옵션 추가
    ```
    bin/kafka-console-consumer.sh --bootstrap-server my-kafka:9092 --topic hello.kafka --from-beginning --property print.key=true --property key.separator="-" --from-beginning --max-messages 1
    ```
    - <img width="264" alt="image" src="https://github.com/hesongg/kafka-study/assets/77953474/0be7c1fe-aba5-4624-9106-d3cd9fe73f22">
    - 최초 데이터 하나만 읽고 종료되는 것을 확인 가능하다.

- 특정 파티션 데이터 조회
    ```
    bin/kafka-console-consumer.sh --bootstrap-server my-kafka:9092 --topic hello.kafka --from-beginning --property print.key=true --property key.separator="-" --from-beginning --partition 0
    ```
    - <img width="175" alt="image" src="https://github.com/hesongg/kafka-study/assets/77953474/d7fa953b-8ca8-4bd1-a73d-5f0f48960530">
    - 파티션이 하나라서 모든 데이터가 조회됨

- 그룹 옵션 사용하여 데이터 조회
    ```
    bin/kafka-console-consumer.sh --bootstrap-server my-kafka:9092 --topic hello.kafka --group hello-group --from-beginning
    ```
    - <img width="230" alt="image" src="https://github.com/hesongg/kafka-study/assets/77953474/5241e00e-8b4f-4fed-8572-f0163b88816b">
    - hello-group 이라는 컨슈머 그룹은 ```testtesttest``` 레코드까지 읽었다고 커밋한다.

- 위의 커밋 데이터는 ```__consumer_offsets``` 라는 카프카 토픽에 저장된다.
    ```
    bin/kafka-topics.sh --bootstrap-server my-kafka:9092 --list
    ```
    - <img width="563" alt="image" src="https://github.com/hesongg/kafka-study/assets/77953474/d96633c1-1de9-44eb-8310-d532f2e5a26d">
    - 토픽 list 조회로 오프셋 토픽 확인 가능

<br>

#### kafka-consumer-groups.sh

- 컨슈머 그룹은 따로 생성하는 명령을 날리지 않고 컨슈머를 동작할 때 컨슈머 그룹이름을 지정하면 새로 생성된다.
    - 생성된 컨슈머 그룹에 대해서 커밋을 날려서 오프셋 데이터가 ```__consumer_offsets``` 라는 내부 카프카 토픽에 저장된다는 것을 확인했다.

- 생성된 컨슈머 그룹의 리스트를 kafka-consumer-groups.sh 명령어로 확인 가능하다.

- --describe 옵션을 사용하면
    - 해당 컨슈머 그룹이 어떤 토픽을 대상으로 어떤 레코드(몇번 오프셋)까지 가져갔는지 상태는 무엇인지 등을 확인 가능하다.
    - 파티션 번호, 현재까지 가져간 레코드의 오프셋, 파티션 마지막 레코드의 오프셋, 컨슈머 랙, 컨슈머 ID, 호스트 등 조회 가능
    - 이렇게 컨슈머의 상태를 조회할 때 유용하다.
    - 컨슈머 그룹을 운영할 때는 컨슈머 랙을 모니터링하는 것이 정말 중요하다.
        - 컨슈머 그룹을 운영하면 컨슈머 랙을 모니터링하기 유용하다. 라는 뜻인듯

- --reset-offsets : 오프셋 리셋
    - 리셋 오프셋으로 특정 기간에 대해서 옵션을 주면
    - 컨슈머 그룹은 해당 데이터를 어느 오프셋부터 가져올지 정하는 옵션
    - 오프셋 리셋 종류
        - --to-earliest : 가장 처음 오프셋(작은 번호)으로 리셋
        - --to-latest : 가장 마지막 오프셋(큰 번호)으로 리셋
        - --to-current : 현 시점 기준 오프셋으로 리셋
        - --to-datetime {YYYY-MM-DDTHH:mmSS.sss} : 특정 일시로 오프셋 리셋(레코드 타임스탬프 기준)
        - --to-offset {long} 특정 오프셋으로 리셋
        - --shift-by {+/- long} : 현재 컨슈머 오프셋에서 앞뒤로 옮겨서 리셋

- 컨슈머그룹 리스트 확인
    ```
    bin/kafka-consumer-groups.sh --bootstrap-server my-kafka:9092 --list
    ```

- 특정 그룹에대한 설명 출력
    ```
    bin/kafka-consumer-groups.sh --bootstrap-server my-kafka:9092 --group hello-group --describe
    ```
    - <img width="934" alt="image" src="https://github.com/hesongg/kafka-study/assets/77953474/336b5cda-c654-45fc-abb3-e6b2c140894e">

- 프로듀서로 데이터 추가 후 LOG-END-OFFSET 다시 확인 테스트
    - <img width="727" alt="image" src="https://github.com/hesongg/kafka-study/assets/77953474/09ebe43b-abcc-4ffe-9607-45ab883a1e53">
    - <img width="935" alt="image" src="https://github.com/hesongg/kafka-study/assets/77953474/483f1b87-4d3c-43f4-9611-04e6ce680db3">
    - 컨슈머가 추가된 데이터를 처리하기 전
        - CURRENT-OFFSET : 15
            - 컨슈머가 현재 어느 오프셋까지 읽었는지에 대한 정보
        - LOG-END-OFFSET : 22
            - 마지막 오프셋
        - LAG : 7
            - 프로듀서에서 넣은 마지막 오프셋과 컨슈머가 처리한 오프셋 차이
            - 지연 발생의 크기

- 지연을 따라 잡으려면?
    - hello-group 이라는 컨슈머 그룹이 hello.kafka 라는 토픽에 대해서 데이터를 가져가면 됨
    ```
    bin/kafka-console-consumer.sh --bootstrap-server my-kafka:9092 --topic hello.kafka --group hello-group
    ```
    - <img width="340" alt="image" src="https://github.com/hesongg/kafka-study/assets/77953474/3a103719-4e07-4295-9a26-df43da4b2a93">
    - <img width="793" alt="image" src="https://github.com/hesongg/kafka-study/assets/77953474/d0fd9ee1-31cb-4e45-a7e8-aac5fdefcf43">
    - 컨슈머 그룹 실행 후 랙이 0 이 된것을 확인 가능
    - 현재 컨슈머가 실행되고 있는 상태기 때문에 컨슈머id 와 호스트 정보도 프린트되는 것을 확인 가능

- 리셋 오프셋
    - --to-earliest
        ```
        bin/kafka-consumer-groups.sh --bootstrap-server my-kafka:9092 --group hello-group --topic hello.kafka --reset-offsets --to-earliest --execute
        ```
        - <img width="597" alt="image" src="https://github.com/hesongg/kafka-study/assets/77953474/70505efc-938a-4170-9f95-6c7247c62150">
        - 실행하면 NEW-OFFSET 이 지정되는 것을 확인 가능하다.
        - hello-group 이라는 컨슈머 그룹이 hello.kafka 토픽의 데이터를 가져가게되면
        - <img width="870" alt="image" src="https://github.com/hesongg/kafka-study/assets/77953474/e6b80ac4-a1e7-4885-b1ee-e96032497fcd">
        - 처음 데이터부터 모두 들고오는 것을 확인 가능하다.

<br>

#### 그 외 커맨드 라인 툴

- ```kafka-producer-perf-test.sh```
    - 카프카 프로듀서로 퍼포먼스 측정 시 사용
    - 네트워크 성능 및 퍼포먼스 확인 가능
    ```
    bin/kafka-producer-perf-test.sh \
    --producer-props bootstrap.servers=my-kafka:9092 \
    --topic hello.kafka \
    --num-records 10 \
    --throughput 1 \
    --record-size 100 \
    --print-metric
    ```
    - <img width="947" alt="image" src="https://github.com/hesongg/kafka-study/assets/77953474/f1f953e7-e4f5-44d1-aaa3-87265ca6d1f9">


- ```kafka-consumer-perf-test.sh```
    - 카프카 컨슈머로 퍼포먼스 측정할 때 사용된다.
    - 카프카 브로커와 컨슈머(여기서는 해당 스크립트를 돌리는 호스트)간의 네트워크를 체크할 때 사용 가능
    - <img width="841" alt="image" src="https://github.com/hesongg/kafka-study/assets/77953474/8cf003ed-085e-4044-9ceb-de877b8718b4">
    - 로컬에서 동일 스크립트 구동 시에는 테스트 결과가 노출되지 않음
        - 프로듀서가 동작 중이지 않아서 그런듯?

- ```kafka-reassign-partitions.sh```
    - 리더 파티션이 하나의 브로커에 몰려서 구성될 때가 있음
    - 리더 파티션과 팔로워 파티션을 적절하게 분산해서 운영하기 위해 사용
    - <img width="916" alt="image" src="https://github.com/hesongg/kafka-study/assets/77953474/5c1878ce-84d2-4165-ab4f-d13e784d79bb">
    - 리더 파티션과 팔로워 파티션 위치 변경 가능
    - 카프카 브로커에는 ```auto.leader.rebalance.enable``` 옵션이 있는데 기본값은 true
        - 클러스터 단위에서 리더 파티션을 자동 리밸런싱하도록 도와준다.
    - 브로커의 백그라운드 스레드가 일정한 간격으로 리더의 위치를 파악하고 필ㄹ요시 리더 리밸런싱을 통해 리더의 위치가 알맞게 배분된다.
    - 운영 환경에서 리더 파티션이 알맞게 배분되어있는지 모니터링하는 부분이 중요하다.

- ```kafka-delete-record.sh```
    - 레코드를 삭제하는 것 같지만 low watermark(워터 마크)를 표시하는 것과 같다.
    - <img width="713" alt="image" src="https://github.com/hesongg/kafka-study/assets/77953474/2193767c-471e-4b49-b068-fbf9969c3832">
    - 이렇게 수행하면 파티션 0 의 오프셋 0~5 까지의 데이터를 삭제한다는 의미이다.
    - 설명이 좀 헷갈리는데.. 세그먼트를 삭제하는 것이 아니라 워터 마크를 남겨서 컨슈머 클라이언트가 earliest 로 메시지를 요청할 경우 low watermark 이후 레코드부터 가져가도록 하는 것임

- ```kafka-dump-log.sh```
    - 특정 파일에 대해서 상세 로그를 확인 필요한 경우 사용
    - 일반적인 애플리케이션 개발 시에는 잘 사용되지않음
    - 세그먼트 로그에대해서 확인 필요한 경우 사용
    - <img width="592" alt="image" src="https://github.com/hesongg/kafka-study/assets/77953474/2864000c-7244-4ece-a5c9-83d36b9d12d4">

<br>

#### 토픽을 생성하는 두가지 방법

- 1번. 카프카 컨슈머 또는 프로듀서가 카프카 브로커에 생성되지 않은 토픽에 대해서 데이터 요청 시
    - 파티션 등의 설정 정보는 브로커의 기본 옵션으로 설정된다.
    - 토픽마다 설정 정보를 다르게 세팅해야되는 경우가 있음
        - 데이터 처리량이 많아야하는 대용량 토픽의 경우 파티션 개수를 더 크게 설정할 수도 있다.
        - 단기간 데이터 처리만 필요한 경우 토픽의 리텐션 옵션을 짧게 설정해야할 수도 있다.
    - 브로커의 auto create 옵션이 true 인 경우에만 브로커의 기본 설정으로 토픽이 생성된다.
- 2번. CLI 툴로 명시적으로 토픽을 생성할 때

- 토픽을 효과적으로 유지보수하기 위해서는 토픽을 명시적으로 생성하는 것을 추천한다.
    - 위 2번의 방식

<br>

#### 카프카 브로커와 로컬 커맨드 라인 툴 버전을 맞춰야 하는 이유

- 카프카 브로커로 CLI 툴 명령을 내릴 때 브로커의 버전과 커맨드 라인 툴 버전을 반드시 맞춰서 사용하는 것을 권장한다.
- 브로커의 버전이 업그레이드 됨에 따라 커맨드 라인 툴의 상세 옵션이 달라지기 때문에 버전 차이로 인한 명령어 실행 오류 발생 가능
