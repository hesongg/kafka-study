# 1. 카프카 - 기본 개념
## 인프런 - "[아파치 카프카 애플리케이션 프로그래밍] 개념부터 컨슈머, 프로듀서, 커넥트, 스트림즈까지!" 를 보고 정리한 내용

<br>

### 빅데이터 파이프라인에 적합한 카프카의 특징

1. 높은 처리량
   - 카프카 프로듀서에서 메시지를 배치로 묶어서 전송하는 옵션이 있다.
     - 데이터가 많은 경우 묶어서 네트워크 전송 비용을 줄일 수 있음
   - 동일 목적 데이터를 여러 파티션에 분배하고 데이터 병렬 처리
     - ex) 컨슈머만큼 파티션 생성하여 처리량 증가 가능
2. 확장성
   - 데이터가 얼마나 들어올지 예측이 어려움
     - ex) 특정 이벤트 발생하는 경우
   - 가변적인 환경에서 안정적으로 확장 가능하도록 설계
   - 데이터가 많으면 클러스터의 브로커 개수 늘려 스케일 아웃
     - 클러스터 : 여러 개의 브로커로 구성된 구조
   - 반대로 데이터가 적어지면 브로커 개수를 줄여 스케일 인도 가능하다.
   - 이렇게 클러스터 스케일 아웃/인 과정을 무중단으로 운영 가능하여 안정적인 시스템 운영이 가능하다.
3. 영속성
   - 영속성 : 데이터 생성한 프로그램이 종료되더라도 사라지지 않은 데이터의 특성
   - 카프카는 다른 메시징 플랫폼과 다르게 전송받은 데이터를 메모리에 저장하지않고 파일 시스템에 저장
     - 파일 I/O 성능 향상을 위해 페이지 캐시 영역을 메모리에 따로 생성하여 사용
     - 한번 읽은 파일 내용은 메모리에 저장하여 읽는 방식으로 속도가 높다
4. 고가용성
   - 3개 이상의 서버들로 운영되는 카프카 클러스터는 일부 서버에 장애가 발생하여도 무중단으로 안전하고 지속적으로 데이터 처리 가능
   - 데이터 복제(replication) 를 통한 고가용성 특징을 가짐

<br>

### 빅데이터 아키텍처 종류

- 초기 빅데이터 플랫폼
  - end to end 방식
- 람다 아키텍처
  - 배치 레이어, 스피드 레이어, 서빙 레이어 구성
  - 중복된 데이터 처리 로직 및 관리 영역이 생김
    - 배포 및 디버깅 등 공통으로 관리 불가
- 카파 아키텍처
  - 배치 레이어 제거, 스피드 레이어 및 서빙 레이어로 운영
  - 배치 데이터 스냅샷
    - 변환 기록 로그 방식(timestamp)으로 데이터 배치 처리

<br>

### 카프카 브로커 / 클러스터 / 주키퍼 등 기본 개념

<br>

#### 주키퍼?

<img width="287" alt="image" src="https://github.com/hesongg/kafka-study/assets/77953474/a94a78df-0013-4840-af49-81af61d1d6ed">


카프카 3.X 버전부터 주키퍼 없이 클러스터 운영 가능
- 완벽하게 주키퍼 대체는 하지 못해서 현재는 주키퍼가 있는 카프카 클러스터로 운영 가능

1개 카프카 클러스터는 기본적으로 브로커 3대로 구성
- 50~100 개로 운영하는 케이스도 있고
- 목적에 따라 클러스터를 여러개로 운영하는 케이스도 있음
- 클러스터 구성하지않고 1개 브로커로 운영해도 문제는 없지만
  - 고가용성을 위해 보통 클러스터로 구성하여 운영한다.
  - 분산 저장 data replication, fail over 를 통한 고가용성 보장

<br>

#### 여러개의 카프카 클러스터가 연결된 주키퍼

<img width="541" alt="image" src="https://github.com/hesongg/kafka-study/assets/77953474/478d75f4-c4e2-464d-9fd7-d9155941e78a">

여러 개의 주키퍼를 앙상블로 구성하여 여러개의 카프카 클러스터 연결 가능
- 주키퍼를 클러스터 마다 다르게 가져갈 수 있지만
  - 상황에 따라 다르지만 리소스 낭비 발생가능
- 카프카 3.0 부터는 주키퍼가 없어도 클러스터 동작 가능
  - 당장 사용하기에는 불안정한 듯

<br>

#### 브로커의 역할

컨트롤러
- 클로스터의 다수 브로커 중 한 대가 컨트롤러의 역할 수행
- 브로커 상태가 비정상이라면 클러스터에서 제외하고, 브로커에 존재하는 리더 파티션 재분배 등 컨트롤러의 역할이 중

<br>

데이터 삭제
- 브로커만이 데이터를 삭제 가능
- 데이터 삭제는 로그 세그먼트(log segment) 라는 파일 단위로 수행된다.
- 시간 / 용량 단위나
  - compact 옵션 등을 이용한 로직으로 데이터 삭제 수행

<br>

컨슈머 오프셋 저장
- 컨슈머 그룹은 토픽이 특정 파티션으로부터 데이터를 가져가서 처리하고 이 파티션의 어느 레코드까지 가져갔는지 확인하기위해 오프셋을 커밋
- 커밋한 오프셋은 ```_consumer_offsets``` 토픽에 저장
  - 저장된 오프셋을 토대로 컨슈 그룹은 다음 레코드 처리

<br>

그룹 코디네이터
- 코디네이터는 컨슈머 그룹의 상태를 체크, 파티션을 컨슈머와 매칭되도록 분배하는 역할 수행
- 컨슈머가 컨슈머 그룹에서 빠지면 매칭되지 않은 파티션을 정상 컨슈머로 할당하여 끊임없이 데이터가 처리되도록 도와준다.
  - 리밸런스(rebalance) : 파티션을 컨슈머로 재할당하는 과정

<br>

데이터의 저장
- <img width="661" alt="image" src="https://github.com/hesongg/kafka-study/assets/77953474/dea9f819-f0f0-408d-b94d-9717a2182785">

- 카프카 실행 시 ```config/server.properties``` 의 ```log.dir``` 옵션에 정의한 디렉토리에 데이터 저장
  - 토픽 이름과 파티션 번호의 조합으로 하위 디렉토리 생성
- 참고)데이터 정보 (특정 토픽 - n번 파티션 정보)
  - ```.log```
    - 메시지와 메타데이터 저장
  - ```.index```
    - 메시지의 오프셋을 인덱싱한 정보를 담은 파일
  - ```.timeindex```
    - 메시지에 포함된 timestamp 값을 기준으로 인덱싱한 정보
  - 메시지 = 레코드
- 로그와 세그먼트
  - <img width="990" alt="image" src="https://github.com/hesongg/kafka-study/assets/77953474/9f8808e8-7235-40aa-8a06-d5de4ec15de6">

  - 하나의 파일에 정보가 지속적으로 저장되는 것이 아님
  - 파일이 세그먼트 단위로 나뉘어서 저장되는데…
    - 오프셋 번호로 파일 명이 저장됨
      - ex) 000000.log, 000010.log, 000020.log
      - 0000000.log (오프셋 0~9)
      - 0000010.log (오프셋 10~11)
      - 000020.log (active) 
        - (오프셋 20~ 현재 오프셋 정보 저장)
      - 파일 명은 오프셋 시작되는 번호
  - ```log.segment.bytes```
    - 바이트 단위의 최대 세그먼트 크기 지정
    - 기본 값 1GB
  - ```log.roll.ms(hours)```
    - 세그먼트가 신규 생성된 이후 다음 파일로 넘어가는 시간 주기
    - 기본 값 7일
    - 데이터가 bytes 단위를 만족 못하여도 해당 옵션으로 인해 특정 시간이 지나면 다음 파일이 생성 될 수 있음
  - 액티브 세그먼트
    - 가장 마지막 파일 (현재 쓰기가 수행되는 있는 파일)
    - 브로커의 삭제 대상에 포함되지 않음
  - 액티브 세그먼트가 아닌 세그먼트는 retention 옵션에 따라 삭제 대상으로 지정된다.
- 세그먼트와 삭제 주기 - ```cleanup.policy=delete```
  - delete 정책은 파일을 삭제
  - ```rentention.ms(minutes, hours)```
    - 세그먼트 보유할 최대 기간
    - 기본 값 7일
  - ```retention.bytes```
    - 파티션당 로그 적재 바이트 값
    - 기본 값은 -1 (지정하지않음)
  - 액티브 세그먼트는 삭제되지않는 내용을 기억하자
  - ```log.retention.check.interval.ms```
    - 세그먼트가 삭제 영역에 들어왔는지 확인하는 간격
    - 기본 값 5분
  - 참고) 운영 시
    - retention 보유 기간은 일반적으로 3일정도로 운영
  - 카프카의 데이터는 세그먼트 단위로 삭제가 발생하기 때문에 로그 단위(레코드 단위) 로 개별 삭제는 불가능
  - 로그(레코드)의 메시지 키, 메시지 값, 오프셋, 헤더 등 이미 적재된 데이터에 대해서 수정 또한 불가능
  - 이러한 이유로 프로듀서에서 데이터보낼 때 / 컨슈머에서 데이터 처리할 때 validation 하는 로직을 구현하는게 중요하다.
- ```cleanup.policy=compact```
  - 토픽 압축 정책은 일반적으로 생각하는 압축과는 다른 개념
  - 여기서 압축이란 키 별로 해당 메시지 키의 레코드 중 오래된 데이터를 삭제하는 정책을 뜻한다.
  - 삭제 정책과 다르게 일부 레코드만 삭제될 수 있음
  - 압축도 액티브 세그먼트를 제외한 데이터가 대상이다.
  - 가장 최신의 key-value store 로 사용이 필요한 경우 활용 가능
  - 테일/헤드 영역, 클린/더티 로그
    - 테일 영역
      - 압축 정책에 의해 압축이 완료된 레코드들
      - 클린(clean) 로그 라고도 부른다.
      - 중복된 메시지 키가 없다.
    - 헤드 영역
      - 압축 되기 전 레코드들
      - 더티(dirty) 로그 라고도 부른다.
      - 중복된 메시지키가 있다.
    - ```min.cleanable.dirty.ratio```
      - 데이터의 압축 시작 시점은 해당 옵션 값을 따른다.
      - 액티브 세그먼트를 제외한 세그먼트에 남아있는 테일 영역 레코드 개수와 헤드 영역 레코드 개수의 비율을 뜻한다.
      - ex) 설정 예시
        - 0.5 로 설정한다면?
          - 클린 로그 == 더티 로그 인 경우 압축 실행
        - 0.9 와 같이 크게 설정한다면?
          - 한번 압축할 때 많은 데이터가 줄어들어 압축 효과 좋음
          - 하지만 0.9 비율 될 때까지 용량을 차지하여 용량 효율이 좋지 않음
        - 0.1 과 같이 작게 설정한다면?
          - 압축이 자주 일어나서 가장 최신 데이터만 유지 가능
          - 압축이 자주 발생하여 브로커에 부담 발생

<br>

복제
- 데이터의 복제(replication)는 카프카를 장애 허용 시스템(fault tolerant system)으로 동작하도록 하는 원동력이다.
- 복제 이유: 클러스터로 묶인 브로커 일부가 장애 발생하여도 데이터를 유실하지않고 안전하게 사용 가능
- 카프카의 데이터 복제는 파티션 단위로 이루어진다.
- 토픽 생성 시 파티션의 복제 개수(replication factor) 도 같이 설정되는데, 직접 옵션을 선택하지 않으면 브로커에 설정된 옵션 값을 따라간다.
- 복제 개수의 최솟값은 1(복제 없음)
- 최댓값은 브로커 개수만큼 설정하여 사용 가능
- 보통 상용환경에서는 2~3 정도로 설정해서 운영하는게 대부분
- 복제된 파티션은 리더와 팔로워로 구성된다.
- 리더: 프로듀서 또는 컨슈머와 직접 통신하는 파티션
- 팔로워: 나머지 복제 데이터를 가지고있는 파티션
- 파티션 복제로 인해 나머지 브로커에도 파티션의 데이터가 복제되므로 복제 개수만큼 저장 용량이 증가하는 단점
- 하지만 복제를 통해 데이터를 안전하게 사용할 수 있다는 강력한 장점
   - 카프카 운영 시 2 이상의 복제 개수를 정하는 것이 중요하다.
- 브로커 장애 발생 시
   - 브로커 다운되면 팔로워 파티션 중 하나가 리더 파티션 지위를 넘겨받는다. (승급)
   - 데이터 유실 방지 / 새로운 리더 파티션이 컨슈머나 프로듀서와 데이터를 주고 받을 수 있음
- 운영 시
   - 데이터 종류마다 다른 복제 개수 설정하기도 함
   - 상황에 따라서 토픽마다 복제 개수를 다르게 설정하여 운영하기도 함
   - 데이터 일부 유실되어도 무관하고 데이터 처리 속도가 중요하다면 1 또는 2 로 설정
      - ex) metric 등 실시간으로 수집되지않아도 상관없는 데이터의 경우
   - 금융 정보와 같이 유실이 일어나면 안되는 데이터의 경우 복제 개수를 3으로 설정

<br>

#### ISR (In-Sync-Replicas)

- ISR 은 리더 파티션과 팔로워 파티션이 모두 싱크가 된 상태를 뜻한다.
    - 파티션의 모든 데이터가 동기화된 상태
- 리더 파티션의 데이터를 모두 복제하지 못한 상태에서 싱크가 되지않은 팔로워 파티션이 리더 파티션으로 선출되면 데이터 유실 가능
- 유실이 발생하더라도 서비스를 중단하지 않고 지속적으로 토픽을 사용하고 싶다면 ISR 이 아닌 팔로워 파티션을 리더로 선출하도록 설정 가능
    - ```unclean.leader.election.enable=true``` : 유실을 감수함. 복제가 안된 팔로워 파티션을 리더로 승급
    - ```unclean.leader.election.enable=false``` : 유실을 감수하지 않음. 해당 브로커가 복구될 때까지 중단.
- 일반적으로 지속적인 서비스 제공을 위해 유실을 감수한다면 해당 옵션 true 로 설정함.
- 금융 서비스 같이 데이터 유실 여부가 중요한 경우 false 옵션 사용 필요

<br>

#### 토픽과 파티션

- 토픽은 카프카에서 데이터를 구분하기 위해 사용하는 단위
- 토픽은 1개 이상의 파티션을 소유
- 파티션에는 프로듀서가 보낸 데이터들이 들어가서 저장되는데, 이 데이터를 레코드(record) 라고 부른다.
- 파티션은 큐(queue) 자료구조와 비슷한 구조 (FIFO)
    - 다만 일반적인 큐와 다르게 카프카에서는 데이터가 읽어져도 레코드를 삭제하지 않는다.
- 여러 consumer 에서 동일한 데이터를 여러번 읽을 수 있다는게 카프카의 가장 큰 특징이다.

<br>

토픽 생성 시 파티션이 배치되는 방법
<img width="830" alt="image" src="https://github.com/hesongg/kafka-study/assets/77953474/36045f95-851b-478b-8886-6db885289efd">

- 파티션이 5개인 토픽을 생성했을 때 0번 브로커부터 시작하여 round-robin 방식으로 리더 파티션들이 생성된다.
- 카프카 클라이언트는 리더 파티션이 있는 브로커와 통신하여 데이터를 주고 받으며 여러 브로커에 골고루 네트워크 통신 수행
    - 부하 분산
- 데이터가 특정 서버(브로커)와 통신이 집중되는(hot spot) 현상을 막고 선형 확장(linear scale out)을 하여 데이터가 많아져도 자연스럽게 대응이 가능하다.

<img width="833" alt="image" src="https://github.com/hesongg/kafka-study/assets/77953474/2efe3bc6-1a7b-4d1f-82a5-780a47a70cef">
- 리더 파티션 선정 및 데이터 복제가 균등하게 이루어지는 것을 확인 가능하다.

<br>

특정 브로커에 파티션이 쏠린 현상
- 하나의 브로커에 리더 파티션이 몰리는 케이스가 있다.
- 특정 브로커에 리소스 사용량이 몰리는 현상을 유발할 수 있음
- 이런 현상을 막는 것이 카프카 클러스터 운영에 중요한 부분이다.
- 특정 브로커에 파티션이 몰리는 경우
    - ```kafka-reassign-partitions.sh``` 명령으로 파티션 재분배 가능
 
<br>

파티션 개수와 컨슈머 개수의 처리량
- <img width="598" alt="image" src="https://github.com/hesongg/kafka-study/assets/77953474/52fa3361-7912-4ad8-84ec-fcecca94ed69">

- 파티션-컨슈머는 기본적으로 1:1 관계이다.
    - 파티션 1개일 때 컨슈머가 1개 더 생기더라도 1:2 로 매핑될 수는 없다.  
    - 물론 컨슈머에 장애가 발생하거나 하는 경우 하나의 컨슈머가 여러 파티션 레코드를 처리 가능하다.
- 파티션은 카프카 병렬 처리의 핵심으로써 그룹으로 묶인 컨슈머들이 레코드를 병렬로 처리할 수 있도록 매칭된다.
- 컨슈머의 처리량이 한정된 상황에서 많은 레코드를 병렬로 처리하는 좋은 방법은 컨슈머의 개수를 늘려 스케일 아웃하는 것
- 컨슈머 개수와 파티션 개수를 같이 늘리면 처리량이 증가하는 효과가 있음
- 일반적인 운영 방법
    - ex) 프로듀서가 초당 10개 데이터 생성하는 경우
        - 파티션, 컨슈머 개수를 보수적으로 20개 정도 잡아서 운영한다.
- 파티션 개수를 줄이는 것은 불가능
    - 카프카에서 파티션 개수를 줄이는 것은 지원하지 않는다.
    - 파티션 늘릴 때는 신중하게 파티션 개수를 정해야 한다.
    - 한번 늘리면 줄이는 것은 불가능하기 때문에 토픽을 삭제하고 재생성하는 방법 외에는 없다

<br>

#### 레코드

- 레코드는 타임스탬프, 헤더, 메시지 키, 메시지 값, 오프셋으로 구성
- 프로듀서가 생성한 레코드가 브로커에 전송되어 저장될 때 오프셋 또는 옵션에 따라서 타임스탬프가 지정되어 저장된다.
    - 기본적으로 브로커는 오프셋을 가지고 있지않고, 레코드가 브로커에 저장될 때 오프셋을 가지고 있다는 점을 기억하자.
- 브로커에 한번 저장된 레코드는 수정 불가능
- 로그 리텐션 기간 또는 용량에 따라서만 삭제가 된다.

<br>

레코드-타임스탬프
- 스트림 프로세싱에서 활용하기 위해 시간을 저장하는 용도로 사용
- 타임스탬프는 Unix timestamp 가 포함
- 프로듀서에서 따로 설정하지않으면 기본 값으로 ProducerRecord 생성 시간(Create Time)이 들어간다.
    - 또는 옵션에 따라서 브로커 적재 시간(LogAppendTime) 으로 설정 가능
    - 해당 옵션은 토픽 단위로 설정 가능
    - ```message.timestamp.type```
 
<br>

레코드-오프셋
- 레코드의 오프셋은 프로듀서가 생성한 레코드에는 존재하지 않음
- 프로듀서가 전송한 레코드가 브로커에 적재될 때 오프셋이 지정
- 오프셋은 0부터 시작되고 1씩 증가
- 컨슈머는 오프셋을 기반으로 처리가 완료된 데이터와 앞으로 처리해야할 데이터를 구분
- 각 메시지는 파티션 별로 고유한 오프셋을 가지므로 컨슈머에서 중복 처리를 방지하기위한 목적으로도 사용

<br>

레코드-헤더
- 레코드의 헤더는 key/value 데이터 추가 가능
- 레코드의 스키마 버전이나 포맷과 같이 데이터 프로세싱에 참고할만한 정보를 담아서 사용 가능

<br>

레코드-메시지 키
- 메시지 키는 처리하고자 하는 메시지 값의 분류를 위한 용도
    - 이를 파티셔닝이라고 부른다.
- 파티셔닝에 사용하는 메시지 키는 파티셔너(Partitioner)에 따라 토픽의 파티션 번호가 정해진다.
- 메시지 키는 필수 값이 아님. 지정하지않으면 null 로 설정
- 메시지 키가 null 인 레코드는 특정 토픽의 파티션에 라운드 로빈으로 전달된다.
    - default 동작이라고 보면 될 듯
- null 이 아닌 메시지 키는 해쉬 값에 의해서 특정 파티션에 매핑되어 전달된다.
    - (기본 파티셔너의 경우)
    - 순서 보장 필요한 경우, 메시지 분류가 필요한 경우
- 분류가 필요 없고 모든 데이터를 병렬 처리하고 싶은 경우 키를 지정하지 않으면 됨

<br>

레코드-메시지 값
- 레코드의 메시지 값은 실질적으로 처리할 데이터가 담기는 공간
- 메시지 값의 포맷은 제네릭으로 사용자에 의해 지정된다.
    - 다양한 형태로 활용 가능
- 필요에 따라 사용자 지정 포맷으로 직렬화/역직렬화 클래스를 만들어 사용도 가능하다.
- 브로커에 저장된 레코드의 메시지 값은 어떤 포맷으로 직렬화되어 저장되었는지 알 수 없어서 컨슈머는 미리 역직렬화 포맷을 알고 있어야 한다.
- 대부분 string 으로 직렬화/역직렬화하는 것이 일반적인 사용 방법 (with json)
    - int 데이터만 필요한 경우 공간 낭비가 생길 수 있음

<br>

#### 유지보수하기 좋은 토픽 이름

토픽 이름 제약 조건
- 빈 문자열 토픽 이름은 지원하지 않는다
- 토픽 이름은 마침표 하나(.) 또는 마침표 둘(..) 로 생성될 수 없다.
- 토픽 이름 길이: 249자 미만
- 토픽 이름응 영어 대/소문자와 숫자 0~9 그리고 마침표(.), 언더바(_), 하이픈(-) 조합으로 생성 가능
   - 이외의 문자열이 포함된 토픽 이름은 생성 불가하다.
- 카프카 내부 로직 관리 목적으로 사용되는 2개 토픽과 동일한 이름으로 생성 불가능
   - ```_consumer_offsets```, ```_transaction_state```
- 토픽 이름에 마침표와 언더바가 동시에 들어가면 안된다.
   - 생성은 되지만 사용시 이슈 발생 가능
   - 마침표, 언더바가 들어간 토픽 이름을 사용하면 WARNING 메시지가 뜬다.

<br>

의미 있는 토픽 이름 작명 방법
- 토픽 이름은 데이터의 얼굴이다. 유지보수 시 토픽이름이 크게 중요함
- 카프카는 토픽 이름 변경을 지원하지 않음
   - 이름 변경하려면 삭제 후 다시 생성하는 방법 밖에 없다.

<br>

토픽 작명의  템플릿과 예시
- <환경>.<팀-명>.<애플리케이션-명>.<메시지-타입>
   - 예시) prd.marketing-team.sms-platform.json
- <프로젝트-먕>.<서비스-명>.<환경>.<이벤트-명>
- 환경, 서비스명, JIRA 번호, 메시지 타입
- 카프카 클러스터명, 환경, 서비스명, 메시지 타입 등
- 메시지 타입같은 경우 프로듀서에서 직렬화된 데이터 타입을 컨슈머에서 처리하는 용도로 사용 가능

<br>

#### 클라이언트 메타데이터와 브로커  통신

클라이언트 메타데이터
- <img width="634" alt="image" src="https://github.com/hesongg/kafka-study/assets/77953474/31243c45-5fb3-4808-85d1-770f36c31395">
- 카프카 클라이언트는 통신하고자 하는 리더 파티션의 위치를 알기 위해 데이터를 주고(프로듀서) 받기(컨슈머) 전에 메타 데이터를 브로커로부터 전달 받는다.
- 카프카 프로듀서 메타데이터 옵션
    - ```metadata.max.age.ms``` : 메타데이터를 강제로 리프레쉬하는 간격
        - 기본값은 5분
    - ```metadata.max.idle.ms``` : 프로듀서가 유휴상태인 경우 메타데이터를 캐시에 유지하는 기간
        - ex) 프로듀서가 특정 토픽으로 데이터 보낸 이후 지정한 시간이 지나고 나면 강제로 메타데이터 리프레쉬
        - 기본 값은 5분
<br>

클라이언트 메타데이터가 이슈 발생한 경우
- 카프카 클라이언트는 반드시 리더 파티션과 통신해야한다.
- 만약 메타데이터가 현재의 파티션 상태에 맞게 리프레시되지 않은 상태에서 잘못된 브로커로 데이터를 요청한다면?
    - ```LEADER_NOT_AVAILABLE``` 익셉션이 발생
    - 이 에러는 클라이언트(프로듀서 또는 컨슈머)가 데이터를 요청한 브로커에 리더 파티션이 없는 경우 발생
    - 대부분 메타데이터 리프레쉬 이슈로 발생한다.
    - 이 에러가 자주 발생한다면 메타데이터 리프레시 간격을 확인하고, 클라이언트가 정상적인 메타데이터를 가지고 있는지 확인해야함

<br>

XXOXX
10 14 15 16 / 17 18 19




















