# 3. 카프카 CLI 툴
## 인프런 - "[아파치 카프카 애플리케이션 프로그래밍] 개념부터 컨슈머, 프로듀서, 커넥트, 스트림즈까지!" 를 보고 정리한 내용

<br>

### 카프카 커맨드 라인 툴

- 토픽이나 파티션 개수 변경과 같은 명령을 실행해야하는 경우 자주 발생
- 카프카 CLI 툴과 각 툴별 옵션에 대해 알고있어야 한다.
- 카프카의 명령어들은 관련 애플리케이션 개발 및 클러스터 운영 시 자주 쓰인다.
- CLI 툴을 통해 토픽 관련 명령을 실행할 때 필수 옵션과 선택 옵션이 있음
    - 선택 옵션은 지정하지 않을시 브로커에 설정된 기본 설정 값 또는 커맨드 라인 툴의 기본값으로 대체되어 설정된다.
    - 그러므로 CLI 툴을 사용하기 전에 현재 브로커에 옵션이 어떻게 설정되어 있는지 확인한 후에 사용하자.
    - ex) 특정 토픽에대해서 실제 사용할 파티션의 개수가 5개인데, 브로커의 설정된 기본 파티션 개수가 10개인데 토픽 생성시 옵션을 지정해주지 않으면 브로커 설정 값으로 파티션 10개 생성
        - 파티션 개수는 다시 줄이기 불가능하기때문에 문제가 될 수 있음
<br>

#### 실행 관련

- 실행
    - 카프카 설치 및 config 설정 후, 설치 경로에서 주키퍼 실행 후 -> 카프카 실행
    - ```bin/zookeeper-server-start.sh config/zookeeper.properties```
    - ```bin/kafka-server-start.sh config/server.properties```
    
- 브로커 내부에 설정된 옵션 값 조회
    - ```bin/kafka-broker-api-versions.sh --bootstrap-server localhost:9092```
    
- 부트스트랩 서버의 토픽 리스트 조회
    - ```bin/kafka-topics.sh --bootstrap-server localhost:9092 --list```

<br>

#### kafka-topics.sh

- 카프카 클러스터 정보와 토픽 이름만으로 토픽 생성 가능
    - 클러스터 정보와 토픽 이름은 토픽을 만들기 위한 필수 값
    - 토픽은 파티션 개수, 복제 개수 등과 같이 다양한 옵션이 포함되어 있지만 모두 브로커에 설정된 기본 값으로 생성된다.

- 토픽 생성
    - ```bin/kafka-topics.sh --create --bootstrap-server my-kafka:9092 --topic hello.kafka```

- 토픽 설명 조회
    - ```bin/kafka-topics.sh --bootstrap-server my-kafka:9092 --topic hello.kafka --describe```

- 특정 설정으로 토픽 생성
  ```
  bin/kafka-topics.sh --create --bootstrap-server my-kafka:9092 --partitions 10 --replication-factor 1 --topic hello.kafka2 --config retention.ms=172800000
  ```

- 설정 변경 (파티션 10으로 증가)
  ```
  bin/kafka-topics.sh --bootstrap-server my-kafka:9092 --topic test --alter --partitions 10
  ``` 

- 파티션 줄이는 명령어를 수행하면 오류가 발생한다.
    - <img width="841" alt="image" src="https://github.com/hesongg/kafka-study/assets/77953474/a29c21d0-0972-4851-89c2-1ad34dab964a">
    - 다시 줄이기는 어려우니 파티션을 늘릴 때는 꼭 주의해서 설정하자.

<br>

#### kafka-configs.sh

- --alter 와 --add-config 옵션을 사용하여 min.insync.replicas 옵션을 토픽별로 설정 가능
- ```min.insync.replicas```
    - 프로듀서로 데이터를 보낼 때, 컨슈머가 읽을 때 워터마크 용도로도 사용되고
    - 얼마나 안전하게 데이터를 주고 받을지 명확하게 설정할 때 사용되기도 한다.
- 브로커에 설정된 각종 기본 값은 --broker, --all, --describe 옵션을 사용하여 조회 가능
    - 또는 브로커의 server.properties 파일을 보던가..

- 강의와 다르게 kafka-topis.sh 의 --describe 옵션으로 기본 설정된 retention 기간은 따로 안보이는데 뭘까?
    - default config 는 안보이는건지..

- min.insyunc.replicas 옵션 변경
    ```
    bin/kafka-configs.sh --bootstrap-server my-kafka:9092 --alter --add-config min.insync.replicas=2 --topic test
    ``` 

- 카프카 브로커에 설정된 다양한 옵션 값 조회
    ```
    bin/kafka-configs.sh --bootstrap-server my-kafka:9092 --broker 0 --all --describe
    ```

<br>

#### kafka-console-producer.sh

- 토픽에 데이터를 넣을 수 있는 명령어

- 메시지 키를 가지는 레코드를 전송하기 위해서는 몇가지 추가 옵션 작성 필요
    - ```key.separator``` 를 선언하지 않으면 기본 설정은 Tab delimeter(₩t) 이므로 선언하지 않고 메시지를 보내려면 메시지 키를 작성하고 탭키를 누른 뒤 메시지 값을 작성하고 엔터를 누른다.
    - ```parse.key=true" 옵션도 설정
    - 이러한 옵션을 신경 쓰지 않으면 메시지 키가 null 로 설정될 수 있다

- 동일한 키를 가진 레코드들은 토픽의 동일한 파티션으로 저장됨
    - 이렇게 프로듀서에서 메시지키를 지정하여 레코드를 전송하면 데이터 순서 처리 가능 

- 메시지 키가 null 인 경우에는 프로듀서가 파티션으로 전송할 때 레코드 배치 단위로 라운드 로빈으로 전송함    

- 데이터 전송
    ```
    bin/kafka-console-producer.sh --bootstrap-server my-kafka:9092 --topic hello.kafka
    ```
    - <img width="397" alt="image" src="https://github.com/hesongg/kafka-study/assets/77953474/941a4949-95ab-4432-a897-de30d459eee6">
    
- 메시지 키 지정하여 데이터 전송
    ```
    bin/kafka-console-producer.sh --bootstrap-server my-kafka:9092 --topic hello.kafka --property "parse.key=true" --property "key.separator=:"
    ```
    - key value separator 를 ":" 로 지정함
    - <img width="301" alt="image" src="https://github.com/hesongg/kafka-study/assets/77953474/3dae2778-b6ad-4343-b965-d768178f5310">
    - k1 key 를 가지는 레코드들은 동일한 파티션으로 전달된다.

<br>

#### kafka-console-consumer.sh

- 이 CLI 툴은 이름과 같이 컨슈머 역할을 한다.
- 특정 토픽에 있는 데이터를 컨슘해서 안에 있는 데이터를 임시적으로 조회하기위한 용도로 사용
- 필수 옵션으로 --bootstrap-server 에 카프카 클러스터 정보, --topic 에 토픽 이름이 필요
- 추가로 --from-beginning 옵션을 주면 토픽에 저장된 가장 처음 데이터부터 출력한다.
    - 해당 옵션을 설정하지 않으면 실시간으로 들어오고 있는 데이터들만 출력함

- kafka-console-producer.sh 로 보낸 메시지 값이 출력된 것을 확인 가능
- 만약 레코드의 메시지 키와 메시지 값을 확인하고 싶다면 --property 옵션을 사용하면 된다.
    - ```--property print.key=true```
    - ```--property key.separator=-```

- --max-messages
    - 최대 컨슘 메시지 개수 설정
- --partition
    - 옵션을 사용하면 특정 파티션만 컨슘 가능
- --group
    - 컨슈머 그룹을 기반으로 kafka-console-consumer 가 동작한다.
    - 컨슈머 그룹의 역할?
        - 특정 오프셋 까지의 데이터를 커밋시키기위한 용도로 사용
    - 컨슈머 그룹으로 토픽의 레코드를 가져갈 경우 어느 레코드까지 읽었는지에 대한 데이터가 카프카 브로커에 저장된다.

- 특정 토픽 메시지 처음부터 출력
    ```
    bin/kafka-console-consumer.sh --bootstrap-server my-kafka:9092 --topic hello.kafka --from-beginning
    ```
    - <img width="399" alt="image" src="https://github.com/hesongg/kafka-study/assets/77953474/9ea647b1-2a4b-47a6-8b00-ac78f1c4135a">

- 처음부터 읽는데, 메시지 키도 함께 출력
    ```
    bin/kafka-console-consumer.sh --bootstrap-server my-kafka:9092 --topic hello.kafka --from-beginning --property print.key=true --property key.separator="-" --from-beginning
    ```
    - <img width="236" alt="image" src="https://github.com/hesongg/kafka-study/assets/77953474/cd2e0191-0ebe-47c4-9c2f-795e63d97ed6">

- 위의 내용에 max message 옵션 추가
    ```
    bin/kafka-console-consumer.sh --bootstrap-server my-kafka:9092 --topic hello.kafka --from-beginning --property print.key=true --property key.separator="-" --from-beginning --max-messages 1
    ```
    - <img width="264" alt="image" src="https://github.com/hesongg/kafka-study/assets/77953474/0be7c1fe-aba5-4624-9106-d3cd9fe73f22">
    - 최초 데이터 하나만 읽고 종료되는 것을 확인 가능하다.

- 특정 파티션 데이터 조회
    ```
    bin/kafka-console-consumer.sh --bootstrap-server my-kafka:9092 --topic hello.kafka --from-beginning --property print.key=true --property key.separator="-" --from-beginning --partition 0
    ```
    - <img width="175" alt="image" src="https://github.com/hesongg/kafka-study/assets/77953474/d7fa953b-8ca8-4bd1-a73d-5f0f48960530">
    - 파티션이 하나라서 모든 데이터가 조회됨

- 그룹 옵션 사용하여 데이터 조회
    ```
    bin/kafka-console-consumer.sh --bootstrap-server my-kafka:9092 --topic hello.kafka --group hello-group --from-beginning
    ```
    - <img width="230" alt="image" src="https://github.com/hesongg/kafka-study/assets/77953474/5241e00e-8b4f-4fed-8572-f0163b88816b">
    - hello-group 이라는 컨슈머 그룹은 ```testtesttest``` 레코드까지 읽었다고 커밋한다.

- 위의 커밋 데이터는 ```__consumer_offsets``` 라는 카프카 토픽에 저장된다.
    ```
    bin/kafka-topics.sh --bootstrap-server my-kafka:9092 --list
    ```
    - <img width="563" alt="image" src="https://github.com/hesongg/kafka-study/assets/77953474/d96633c1-1de9-44eb-8310-d532f2e5a26d">
    - 토픽 list 조회로 오프셋 토픽 확인 가능


















