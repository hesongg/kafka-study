# 카프카 - 기본 개념

### 빅데이터 파이프라인에 적합한 카프카의 특징

1. 높은 처리량
   - 카프카 프로듀서에서 메시지를 배치로 묶어서 전송하는 옵션이 있다.
     - 데이터가 많은 경우 묶어서 네트워크 전송 비용을 줄일 수 있음
   - 동일 목적 데이터를 여러 파티션에 분배하고 데이터 병렬 처리
     - ex) 컨슈머만큼 파티션 생성하여 처리량 증가 가능
2. 확장성
   - 데이터가 얼마나 들어올지 예측이 어려움
     - ex) 특정 이벤트 발생하는 경우
   - 가변적인 환경에서 안정적으로 확장 가능하도록 설계
   - 데이터가 많으면 클러스터의 브로커 개수 늘려 스케일 아웃
     - 클러스터 : 여러 개의 브로커로 구성된 구조
   - 반대로 데이터가 적어지면 브로커 개수를 줄여 스케일 인도 가능하다.
   - 이렇게 클러스터 스케일 아웃/인 과정을 무중단으로 운영 가능하여 안정적인 시스템 운영이 가능하다.
3. 영속성
   - 영속성 : 데이터 생성한 프로그램이 종료되더라도 사라지지 않은 데이터의 특성
   - 카프카는 다른 메시징 플랫폼과 다르게 전송받은 데이터를 메모리에 저장하지않고 파일 시스템에 저장
     - 파일 I/O 성능 향상을 위해 페이지 캐시 영역을 메모리에 따로 생성하여 사용
     - 한번 읽은 파일 내용은 메모리에 저장하여 읽는 방식으로 속도가 높다
4. 고가용성
   - 3개 이상의 서버들로 운영되는 카프카 클러스터는 일부 서버에 장애가 발생하여도 무중단으로 안전하고 지속적으로 데이터 처리 가능
   - 데이터 복제(replication) 를 통한 고가용성 특징을 가짐


### 빅데이터 아키텍처 종류와 카프카의 미래

#### 데이터 레이크 아키텍처와 카프카의 미래
- 초기 빅데이터 플랫폼
  - end to end 방식
- 람다 아키텍처
  - 배치 레이어, 스피드 레이어, 서빙 레이어 구성
  - 중복된 데이터 처리 로직 및 관리 영역이 생김
    - 배포 및 디버깅 등 공통으로 관리 불가
- 카파 아키텍처
  - 배치 레이어 제거, 스피드 레이어 및 서빙 레이어로 운영
  - 배치 데이터 스냅샷
    - 변환 기록 로그 방식(timestamp)으로 데이터 배치 처리

### 카프카 브로커 / 클러스터 / 주키퍼

#### 주키퍼?

카프카 3.X 버전부터 주키퍼 없이 클러스터 운영 가능
- 완벽하게 주키퍼 대체는 하지 못해서 현재는 주키퍼가 있는 카프카 클러스터로 운영 가능

1개 카프카 클러스터는 기본적으로 브로커 3대로 구성
- 50~100 개로 운영하는 케이스도 있고
- 목적에 따라 클러스터를 여러개로 운영하는 케이스도 있음
- 클러스터 구성하지않고 1개 브로커로 운영해도 문제는 없지만
  - 고가용성을 위해 보통 클러스터로 구성하여 운영한다.
  - 분산 저장 data replication, fail over 를 통한 고가용성 보장

#### 여러개의 카프카 클러스터가 연결된 주키퍼

여러 개의 주키퍼를 앙상블로 구성하여 여러개의 카프카 클러스터 연결 가능
- 주키퍼를 클러스터 마다 다르게 가져갈 수 있지만
  - 상황에 따라 다르지만 리소스 낭비 발생가능
- 카프카 3.0 부터는 주키퍼가 없어도 클러스터 동작 가능
  - 당장 사용하기에는 불안정한 듯

#### 브로커의 역할

컨트롤러
- 클로스터의 다수 브로커 중 한 대가 컨트롤러의 역할 수행
- 브로커 상태가 비정상이라면 클러스터에서 제외하고, 브로커에 존재하는 리더 파티션 재분배 등 컨트롤러의 역할이 중

데이터 삭제
- 브로커만이 데이터를 삭제 가능
- 데이터 삭제는 로그 세그먼트(log segment) 라는 파일 단위로 수행된다.
- 시간 / 용량 단위나
  - compact 옵션 등을 이용한 로직으로 데이터 삭제 수행

컨슈머 오프셋 저장
- 컨슈머 그룹은 토픽이 특정 파티션으로부터 데이터를 가져가서 처리하고 이 파티션의 어느 레코드까지 가져갔는지 확인하기위해 오프셋을 커밋
- 커밋한 오프셋은 ```_consumer_offsets``` 토픽에 저장
  - 저장된 오프셋을 토대로 컨슈 그룹은 다음 레코드 처리

그룹 코디네이터
- 코디네이터는 컨슈머 그룹의 상태를 체크, 파티션을 컨슈머와 매칭되도록 분배하는 역할 수행
- 컨슈머가 컨슈머 그룹에서 빠지면 매칭되지 않은 파티션을 정상 컨슈머로 할당하여 끊임없이 데이터가 처리되도록 도와준다.
  - 리밸런스(rebalance) : 파티션을 컨슈머로 재할당하는 과정

데이터의 저장
- 카프카 실행 시 config/server.properties 의 log.dir 옵션에 정의한 디렉토리에 데이터 저장
  - 토픽 이름과 파티션 번호의 조합으로 하위 디렉토리 생성
- 참고)데이터 정보 (특정 토픽 - n번 파티션 정보)
  - .log
    - 메시지와 메타데이터 저장
  - .index
    - 메시지의 오프셋을 인덱싱한 정보를 담은 파일
  - .timeindex
    - 메시지에 포함된 timestamp 값을 기준으로 인덱싱한 정보
  - 메시지 = 레코드
- 로그와 세그먼트
  - 하나의 파일에 정보가 지속적으로 저장되는 것이 아님
  - 파일이 세그먼트 단위로 나뉘어서 저장되는데…
    - 오프셋 번호로 파일 명이 저장됨
      - ex) 000000.log, 000010.log, 000020.log
      - 0000000.log (오프셋 0~9)
      - 0000010.log (오프셋 10~11)
      - 000020.log (active) 
        - (오프셋 20~ 현재 오프셋 정보 저장)
      - 파일 명은 오프셋 시작되는 번호
  - log.segment.bytes
    - 바이트 단위의 최대 세그먼트 크기 지정
    - 기본 값 1GB
  - log.roll.ms(hours)
    - 세그먼트가 신규 생성된 이후 다음 파일로 넘어가는 시간 주기
    - 기본 값 7일
    - 데이터가 bytes 단위를 만족 못하여도 해당 옵션으로 인해 특정 시간이 지나면 다음 파일이 생성 될 수 있음
  - 액티브 세그먼트
    - 가장 마지막 파일 (현재 쓰기가 수행되는 있는 파일)
    - 브로커의 삭제 대상에 포함되지 않음
  - 액티브 세그먼트가 아닌 세그먼트는 retention 옵션에 따라 삭제 대상으로 지정된다.
- 세그먼트와 삭제 주기 - cleanup.policy=delete
  - delete 정책은 파일을 삭제
  - rentention.ms(minutes, hours)
    - 세그먼트 보유할 최대 기간
    - 기본 값 7일
  - retention.bytes
    - 파티션당 로그 적재 바이트 값
    - 기본 값은 -1 (지정하지않음)
  - 액티브 세그먼트는 삭제되지않는 내용을 기억하자
  - log.retention.check.interval.ms
    - 세그먼트가 삭제 영역에 들어왔는지 확인하는 간격
    - 기본 값 5분
  - 참고) 운영 시
    - retention 보유 기간은 일반적으로 3일정도로 운영
  - 카프카의 데이터는 세그먼트 단위로 삭제가 발생하기 때문에 로그 단위(레코드 단위) 로 개별 삭제는 불가능
  - 로그(레코드)의 메시지 키, 메시지 값, 오프셋, 헤더 등 이미 적재된 데이터에 대해서 수정 또한 불가능
  - 이러한 이유로 프로듀서에서 데이터보낼 때 / 컨슈머에서 데이터 처리할 때 validation 하는 로직을 구현하는게 중요하다.
- cleanup.policy=compact
  - 토픽 압축 정책은 일반적으로 생각하는 압축과는 다른 개념
  - 여기서 압축이란 키 별로 해당 메시지 키의 레코드 중 오래된 데이터를 삭제하는 정책을 뜻한다.
  - 삭제 정책과 다르게 일부 레코드만 삭제될 수 있음
  - 압축도 액티브 세그먼트를 제외한 데이터가 대상이다.
  - 가장 최신의 key-value store 로 사용이 필요한 경우 활용 가능
  - 테일/헤드 영역, 클린/더티 로그
    - 테일 영역
      - 압축 정책에 의해 압축이 완료된 레코드들
      - 클린(clean) 로그 라고도 부른다.
      - 중복된 메시지 키가 없다.
    - 헤드 영역
      - 압축 되기 전 레코드들
      - 더티(dirty) 로그 라고도 부른다.
      - 중복된 메시지키가 있다.
    - min.cleanable.dirty.ratio
      - 데이터의 압축 시작 시점은 해당 옵션 값을 따른다.
      - 액티브 세그먼트를 제외한 세그먼트에 남아있는 테일 영역 레코드 개수와 헤드 영역 레코드 개수의 비율을 뜻한다.
      - ex) 설정 예시
        - 0.5 로 설정한다면?
          - 클린 로그 == 더티 로그 인 경우 압축 실행
        - 0.9 와 같이 크게 설정한다면?
          - 한번 압축할 때 많은 데이터가 줄어들어 압축 효과 좋음
          - 하지만 0.9 비율 될 때까지 용량을 차지하여 용량 효율이 좋지 않음
        - 0.1 과 같이 작게 설정한다면?
          - 압축이 자주 일어나서 가장 최신 데이터만 유지 가능
          - 압축이 자주 발생하여 브로커에 부담 발생
